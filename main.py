import streamlit as st
import pandas as pd
from io import BytesIO
import zipfile
import os
from dotenv import load_dotenv

# ===== ëª¨ë“ˆ import =====
from modules.loader import load_uploaded_files
from modules.quality_checker import summarize_dataframe
from modules.ai_agent import init_azure_client, run_ai_report, run_qa, run_data_processing
from modules.cleaner import preprocess_dataframe
from modules.blob_uploader import upload_to_azure_blob


# ===== í™˜ê²½ ì„¤ì • =====
load_dotenv()
st.set_page_config(page_title="ğŸ§  ë°ì´í„° í’ˆì§ˆ ì ê²€ & ì „ì²˜ë¦¬ ì—ì´ì „íŠ¸", page_icon="ğŸ¤–", layout="wide")

# ===== ì œëª© =====
st.markdown("""
<h2 style='text-align:center; color:#4B9CD3;'>ğŸ§  ë°ì´í„° í’ˆì§ˆ ì ê²€ & ì „ì²˜ë¦¬ ì—ì´ì „íŠ¸</h2>
<p style='text-align:center; color:gray;'>ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•˜ë©´ AIê°€ í’ˆì§ˆ ì ê²€, ì „ì²˜ë¦¬, ì¶”ê°€ ê°€ê³µê¹Œì§€ ìˆ˜í–‰í•©ë‹ˆë‹¤.</p>
""", unsafe_allow_html=True)

# ===== ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” =====
for key, default in {
    "preload_quality_report": None,
    "qa_history": [],
    "ai_history": [],
    "cleaned_results": None,
    "uploaded_file_names": [],
}.items():
    if key not in st.session_state:
        st.session_state[key] = default

# ===== Azure í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” =====
client = init_azure_client()

# ===== 1ï¸âƒ£ íŒŒì¼ ì—…ë¡œë“œ =====
uploaded_files = st.file_uploader(
    "ğŸ“¦ CSV / XLSX / TXT / XML / JSON / ZIP ì—…ë¡œë“œ",
    type=["csv", "xlsx", "txt", "xml", "json", "zip"],
    accept_multiple_files=True,
    key="file_uploader_main"
)

dfs = {}

if uploaded_files:
    current_file_names = [f.name for f in uploaded_files]
    if current_file_names != st.session_state["uploaded_file_names"]:
        st.session_state["uploaded_file_names"] = current_file_names
        st.session_state["preload_quality_report"] = None
        st.session_state["qa_history"] = []

    dfs = load_uploaded_files(uploaded_files)
    st.success(f"âœ… ì´ {len(dfs)}ê°œì˜ ë°ì´í„°ì…‹ ë¡œë“œ ì™„ë£Œ")

    st.markdown("### ğŸ“Š ì—…ë¡œë“œëœ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°")
    for name, df in dfs.items():
        with st.expander(f"ğŸ” {name} ë¯¸ë¦¬ë³´ê¸°"):
            st.dataframe(df.head(), width="stretch")

# ===== 2ï¸âƒ£ í’ˆì§ˆ ì ê²€ ë¦¬í¬íŠ¸ + Q&A =====
if dfs:
    st.markdown("---")
    st.subheader("ğŸ§  ë°ì´í„° í’ˆì§ˆ ì ê²€ ë³´ê³ ì„œ")

    table_summaries = {name: summarize_dataframe(df, name) for name, df in dfs.items()}

    if st.button("ë³´ê³ ì„œ ìƒì„±í•˜ê¸°"):
        with st.spinner("AIê°€ ë°ì´í„° í’ˆì§ˆ ì ê²€ ì¤‘ì…ë‹ˆë‹¤..."):
            ai_report = run_ai_report(client, table_summaries)
            st.session_state["preload_quality_report"] = ai_report
        st.success("âœ… í’ˆì§ˆ ì ê²€ ë¦¬í¬íŠ¸ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")

    if st.session_state["preload_quality_report"]:
        st.markdown(st.session_state["preload_quality_report"])
    else:
        st.info("ì•„ì§ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    # ===== Q&A =====
    st.markdown("---")
    st.subheader("ğŸ’¬ ë¦¬í¬íŠ¸ ê¸°ë°˜ Q&A")

    for user_q, ai_a in st.session_state["qa_history"]:
        with st.chat_message("user"):
            st.markdown(f"**{user_q}**")
        with st.chat_message("assistant"):
            st.markdown(ai_a)

    with st.form(key="qa_form", clear_on_submit=True):
        user_question = st.text_area("ë¦¬í¬íŠ¸ì— ëŒ€í•´ ì§ˆë¬¸í•˜ê¸°", placeholder="ë¦¬í¬íŠ¸ ë‚´ìš©ì— ëŒ€í•´ ê¶ê¸ˆí•œ ì ì„ ì…ë ¥í•˜ì„¸ìš”...")
        submitted = st.form_submit_button("ì§ˆë¬¸í•˜ê¸°")

    if submitted and user_question:
        with st.chat_message("user"):
            st.markdown(user_question)
        with st.spinner("AIê°€ ë‹µë³€ ì¤‘ì…ë‹ˆë‹¤..."):
            ai_answer = run_qa(client, st.session_state["preload_quality_report"], user_question)
        st.session_state["qa_history"].append((user_question, ai_answer))
        with st.chat_message("assistant"):
            available_files = list(st.session_state["cleaned_results"].keys())
        st.markdown(ai_answer)

# ===== 3ï¸âƒ£ ì „ì²˜ë¦¬ ì‹¤í–‰ =====
st.markdown("---")
st.subheader("âš™ï¸ ì „ì²˜ë¦¬ ì‹¤í–‰")

st.caption("""
ë°ì´í„° ì ì¬ ì „ì— ì ìš©í•  ì •ì œ ì‘ì—…ì„ ì„ íƒí•˜ì„¸ìš”.
- ì „ì²´ ì¼ê´„ ì ìš©ì€ ì•ˆì „í•œ í˜•ì‹ ì •ê·œí™”(strip/ì¼€ì´ìŠ¤/ë‚ ì§œ/ìˆ«ì) ìœ„ì£¼ë¡œ ê¶Œì¥ë©ë‹ˆë‹¤.
""")

mode = st.radio(
    "ì „ì²˜ë¦¬ ì ìš© ë²”ìœ„",
    ["ì „ì²´ ì—…ë¡œë“œëœ íŒŒì¼ì— ì¼ê´„ ì ìš©", "ì„ íƒí•œ íŒŒì¼ë§Œ ì²˜ë¦¬"],
    index=0 # âœ… ê¸°ë³¸ ì„ íƒì„ ë‘ ë²ˆì§¸ ì˜µì…˜ìœ¼ë¡œ ì„¤ì •
)

if dfs:
    target_table_name = None
    if mode == "ì„ íƒí•œ íŒŒì¼ë§Œ ì²˜ë¦¬":
        target_table_name = st.multiselect("ì „ì²˜ë¦¬í•  íŒŒì¼ ì„ íƒ", list(dfs.keys()))

    st.markdown("#### ì „ì²˜ë¦¬ ì˜µì…˜ ì„ íƒ")
    fillna_opt = st.checkbox("fillna_zero : ê²°ì¸¡ì¹˜ ê°’ ì±„ìš°ê¸°", value=False)
    dropdup_opt = st.checkbox("drop_duplicates : ì¤‘ë³µí–‰ ì œê±°", value=False)
    strip_opt = st.checkbox("strip_strings : ë¬¸ìì—´ ì•ë’¤ ê³µë°± ì œê±°", value=False)
    case_norm = st.selectbox("ë¬¸ìì—´ ëŒ€ì†Œë¬¸ì ì •ê·œí™”", ["ë³€ê²½ ì•ˆ í•¨", "ì†Œë¬¸ìë¡œ í†µì¼", "ëŒ€ë¬¸ìë¡œ í†µì¼"], index=0)
    convert_dates_opt = st.checkbox("convert_dates : ë¬¸ìì—´ ë‚ ì§œ â†’ datetime ë³€í™˜", value=False)
    convert_num_opt = st.checkbox("convert_numeric_strings : ë¬¸ìì—´ ìˆ«ì â†’ ìˆ˜ì¹˜í˜• ë³€í™˜", value=False)
    drop_empty_cols_opt = st.checkbox("drop_empty_cols : ì™„ì „ ê³µë°± ì»¬ëŸ¼ ì œê±°", value=False)

    if st.button("ğŸš€ ì „ì²˜ë¦¬ ì‹¤í–‰"):
        normalize_case_val = (
            "lower" if case_norm == "ì†Œë¬¸ìë¡œ í†µì¼"
            else "upper" if case_norm == "ëŒ€ë¬¸ìë¡œ í†µì¼"
            else None
        )

        base_opts = {
            "fillna_zero": fillna_opt,
            "drop_duplicates": dropdup_opt,
            "strip_strings": strip_opt,
            "normalize_case": normalize_case_val,
            "convert_dates": convert_dates_opt,
            "convert_numeric_strings": convert_num_opt,
            "drop_empty_cols": drop_empty_cols_opt,
        }

        results_summary = []
        cleaned_results = {}
        targets = target_table_name if mode == "ì„ íƒí•œ íŒŒì¼ë§Œ ì²˜ë¦¬" else list(dfs.keys())

        for t in targets:
            before = dfs[t].copy()
            after = preprocess_dataframe(before, base_opts)
            cleaned_results[t] = after

            changed_types = []
            dtypes_before = before.dtypes.astype(str).to_dict()
            dtypes_after = after.dtypes.astype(str).to_dict()
            for col in after.columns:
                if dtypes_before.get(col) != dtypes_after.get(col):
                    changed_types.append(f"{col}: {dtypes_before.get(col)} -> {dtypes_after.get(col)}")

            results_summary.append({
                "table": t,
                "rows_before": len(before),
                "rows_after": len(after),
                "nulls_before": int(before.isna().sum().sum()),
                "nulls_after": int(after.isna().sum().sum()),
                "changed_types": changed_types
            })

        st.session_state["cleaned_results"] = cleaned_results
        st.session_state["results_summary"] = results_summary
        st.success("âœ… ì „ì²˜ë¦¬ ì™„ë£Œ! AI ê¸°ë°˜ ì¶”ê°€ ì „ì²˜ë¦¬ë¥¼ ì´ì–´ì„œ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

# ===== ì „ì²˜ë¦¬ ê²°ê³¼ ìœ ì§€ í‘œì‹œ =====
if st.session_state.get("cleaned_results") and st.session_state.get("results_summary"):
    st.markdown("### ğŸ“Š ì „ì²˜ë¦¬ ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°")

    for s in st.session_state["results_summary"]:
        table_name = s["table"]
        if table_name not in dfs or table_name not in st.session_state["cleaned_results"]:
            continue

        st.markdown(f"#### â–¶ {table_name} ì²˜ë¦¬ ê²°ê³¼")
        colL, colR = st.columns(2)
        with colL:
            st.markdown("**ì „(before)**")
            st.dataframe(dfs[table_name].head(), width="stretch")
        with colR:
            st.markdown("**í›„(after)**")
            st.dataframe(st.session_state["cleaned_results"][table_name].head(), width="stretch")

    zip_buffer = BytesIO()
    with zipfile.ZipFile(zip_buffer, "w", zipfile.ZIP_DEFLATED) as zf:
        for name, df in st.session_state["cleaned_results"].items():
            csv_bytes = df.to_csv(index=False).encode("utf-8-sig")
            zf.writestr(f"processed_{name.replace('/', '_')}.csv", csv_bytes)
    zip_buffer.seek(0)
    st.download_button(
        label="ğŸ“¥ ë°ì´í„° ZIP ë‹¤ìš´ë¡œë“œ",
        data=zip_buffer,
        file_name="processed_datasets.zip",
        mime="application/zip"
    )

# ===== 4ï¸âƒ£ AI ëª…ë ¹ ê¸°ë°˜ ì¶”ê°€ ì „ì²˜ë¦¬ =====
if st.session_state.get("cleaned_results"):
    st.markdown("---")
    st.subheader("ğŸ¤– AI ëª…ë ¹ ê¸°ë°˜ í›„ì† ì „ì²˜ë¦¬")

    for user_q, ai_a in st.session_state["ai_history"]:
        with st.chat_message("user"):
            st.markdown(f"**{user_q}**")
        with st.chat_message("assistant"):
            st.markdown(ai_a)

    with st.form(key="ai_process_form", clear_on_submit=True):
        ai_target = st.selectbox("ëŒ€ìƒ í…Œì´ë¸” ì„ íƒ", list(st.session_state["cleaned_results"].keys()))
        ai_command = st.text_area("ì „ì²˜ë¦¬ ëª…ë ¹ ì…ë ¥", placeholder="ì˜ˆ: age ì»¬ëŸ¼ ì œê±°í•´ì¤˜ / ë‚ ì§œ í¬ë§· YYYY-MM-DDë¡œ ë°”ê¿”ì¤˜")
        ai_submitted = st.form_submit_button("ëª…ë ¹ ì‹¤í–‰")

    if ai_submitted and ai_command:
        df_before = st.session_state["cleaned_results"][ai_target].copy()

        with st.chat_message("user"):
            st.markdown(f"**{ai_command}**")

        with st.spinner("AIê°€ ëª…ë ¹ì„ í•´ì„í•˜ê³  ë°ì´í„°ë¥¼ ê°€ê³µ ì¤‘ì…ë‹ˆë‹¤..."):
            status, processed_df = run_data_processing(client, df_before, ai_command)

        st.session_state["ai_history"].append((ai_command, status))

        if isinstance(processed_df, pd.DataFrame):
            st.session_state["cleaned_results"][ai_target] = processed_df
            with st.chat_message("assistant"):
                st.success(status)

            st.markdown(f"### ğŸ”„ '{ai_target}' ì „ì²˜ë¦¬ ê²°ê³¼ ë¹„êµ")

            col1, col2 = st.columns(2)
            with col1:
                st.markdown("**ì „(before)**")
                st.dataframe(df_before.head(), width="stretch")
            with col2:
                st.markdown("**í›„(after)**")
                st.dataframe(processed_df.head(), width="stretch")
        else:
            with st.chat_message("assistant"):
                st.warning(processed_df)

# â˜ï¸ Azure Blob Storage ì—…ë¡œë“œ
st.markdown("### â˜ï¸ Azure Blob Storage ì—…ë¡œë“œ")

if st.session_state.get("cleaned_results") and isinstance(st.session_state["cleaned_results"], dict):
    st.info("âœ… ì „ì²˜ë¦¬ ì™„ë£Œ ë°ì´í„°ê°€ ìˆìŠµë‹ˆë‹¤. ì—…ë¡œë“œí•  íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”.")

    available_files = list(st.session_state["cleaned_results"].keys())
    selected_files = st.multiselect("ğŸ“‚ ì—…ë¡œë“œí•  íŒŒì¼ ì„ íƒ", available_files)

    if st.button("ğŸš€ ì„ íƒí•œ íŒŒì¼ ì—…ë¡œë“œ"):
        with st.spinner("Azure Blob Storage ì—…ë¡œë“œ ì¤‘..."):
            upload_to_azure_blob(
                cleaned_results=st.session_state["cleaned_results"],
                selected_files=selected_files,
                container_name=os.getenv("AZURE_CONTAINER_NAME", "raw-data")
            )

else:
    st.info("âš ï¸ ì•„ì§ ì „ì²˜ë¦¬ëœ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ì „ì²˜ë¦¬ í›„ ì—…ë¡œë“œë¥¼ ì§„í–‰í•´ì£¼ì„¸ìš”.")
