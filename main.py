import streamlit as st
import pandas as pd
import numpy as np
import os
import json
from io import StringIO
from dotenv import load_dotenv
from sqlalchemy import create_engine
from langchain_core.prompts import PromptTemplate
from langchain_openai import AzureChatOpenAI

# =========================
# âœ… í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
# =========================
load_dotenv()
AZURE_OPENAI_API_KEY = os.getenv("AZURE_OPENAI_API_KEY")
AZURE_OPENAI_ENDPOINT = os.getenv("AZURE_OPENAI_ENDPOINT")
DEPLOYMENT_NAME = os.getenv("AZURE_OPENAI_DEPLOYMENT_NAME")

# =========================
# âœ… Azure OpenAI ì´ˆê¸°í™”
# =========================
llm = AzureChatOpenAI(
    azure_endpoint=AZURE_OPENAI_ENDPOINT,
    api_key=AZURE_OPENAI_API_KEY,
    api_version="2024-02-01-preview",
    deployment_name=DEPLOYMENT_NAME,
    model="gpt-4.1-mini",
    temperature=0.4
)

# =========================
# âœ… Streamlit ì„¤ì •
# =========================
st.set_page_config(page_title="ğŸ§  AI ë°ì´í„° ì „ì²˜ë¦¬ Copilot", page_icon="ğŸ¤–", layout="wide")
st.title("ğŸ§  AI ê¸°ë°˜ ë°ì´í„° ë¶„ì„ ë° ì „ì²˜ë¦¬ Copilot")

tab1, tab2, tab3, tab4, tab5 = st.tabs([
    "ğŸ“‚ íŒŒì¼ ì—…ë¡œë“œ",
    "ğŸ“Š ë°ì´í„° ë¶„ì„",
    "ğŸ’¬ ì§ˆì˜ì‘ë‹µ",
    "ğŸ§© ì „ì²˜ë¦¬",
    "ğŸ—ƒï¸ MySQL ì ì¬"
])

# =========================
# ğŸ“‚ 1ï¸âƒ£ íŒŒì¼ ì—…ë¡œë“œ íƒ­
# =========================
with tab1:
    uploaded_files = st.file_uploader("ğŸ“¤ ì—¬ëŸ¬ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["csv", "xlsx", "json"], accept_multiple_files=True)
    if uploaded_files:
        st.session_state["dfs"] = {}
        for file in uploaded_files:
            try:
                if file.name.endswith(".csv"):
                    df = pd.read_csv(file)
                elif file.name.endswith(".xlsx"):
                    df = pd.read_excel(file)
                elif file.name.endswith(".json"):
                    df = pd.read_json(file)
                else:
                    st.warning(f"âŒ {file.name}ì€(ëŠ”) ì§€ì›ë˜ì§€ ì•ŠëŠ” í˜•ì‹ì…ë‹ˆë‹¤.")
                    continue
                st.session_state["dfs"][file.name] = df
                st.success(f"âœ… {file.name} ì—…ë¡œë“œ ì™„ë£Œ ({df.shape[0]}í–‰ Ã— {df.shape[1]}ì—´)")
            except Exception as e:
                st.error(f"{file.name} ë¡œë“œ ì˜¤ë¥˜: {e}")

# =========================
# ğŸ“Š 2ï¸âƒ£ ë°ì´í„° ë¶„ì„ íƒ­
# =========================
with tab2:
    if "dfs" not in st.session_state or not st.session_state["dfs"]:
        st.warning("âš ï¸ ë¨¼ì € íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
    else:
        dfs = st.session_state["dfs"]
        st.subheader("ğŸ“‹ ì—…ë¡œë“œëœ ë°ì´í„° ìš”ì•½")

        summaries = {}
        for name, df in dfs.items():
            summary = {
                "shape": df.shape,
                "missing_values": int(df.isnull().sum().sum()),
                "duplicated_rows": int(df.duplicated().sum()),
                "columns": list(df.columns),
                "types": df.dtypes.astype(str).to_dict()
            }
            summaries[name] = summary
            with st.expander(f"ğŸ“„ {name} ë°ì´í„° ìš”ì•½"):
                st.json(summary)
                st.dataframe(df.head(5))

        # =========================
        # ğŸ§  AI ë¶„ì„ ë³´ê³ ì„œ ìƒì„±
        # =========================
        if st.button("ğŸ§  AI ë°ì´í„° ë¶„ì„ ë³´ê³ ì„œ ìƒì„±"):
            prompt = PromptTemplate.from_template("""
            ë‹¤ìŒì€ ì‚¬ìš©ìê°€ ì—…ë¡œë“œí•œ ì—¬ëŸ¬ ë°ì´í„°ì…‹ì˜ ìš”ì•½ ì •ë³´ì…ë‹ˆë‹¤.
            ê° ë°ì´í„°ì…‹ì˜ ì£¼ìš” íŠ¹ì§•, ê²°ì¸¡ì¹˜, ì¤‘ë³µë¥ , ë°ì´í„° í¬ê¸°, ê³µí†µ ì»¬ëŸ¼, ë³‘í•© ê°€ëŠ¥ì„± ë“±ì„ ê¸°ë°˜ìœ¼ë¡œ
            ë°ì´í„° ë¶„ì„ ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì¤˜.
            
            ë°ì´í„° ìš”ì•½:
            {summaries}
            """)
            ai_report = llm.invoke(prompt.format(summaries=json.dumps(summaries, ensure_ascii=False)))
            st.session_state["ai_report"] = ai_report.content
            st.success("âœ… AI ë¶„ì„ ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ!")
            st.markdown("### ğŸ“Š AI ë°ì´í„° ë¶„ì„ ë³´ê³ ì„œ")
            st.write(ai_report.content)

# =========================
# ğŸ’¬ 3ï¸âƒ£ ëŒ€í™”í˜• ì§ˆì˜ì‘ë‹µ íƒ­
# =========================
with tab3:
    if "dfs" not in st.session_state:
        st.warning("âš ï¸ ë¨¼ì € ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”.")
    else:
        st.subheader("ğŸ’¬ ë°ì´í„° ì§ˆì˜ì‘ë‹µ (LLM + Pandas Agent)")

        df_names = list(st.session_state["dfs"].keys())
        selected_file = st.selectbox("ì§ˆì˜í•  ë°ì´í„°ì…‹ ì„ íƒ", df_names)
        df = st.session_state["dfs"][selected_file]

        if "chat_history" not in st.session_state:
            st.session_state.chat_history = []

        query = st.chat_input("ë°ì´í„°ì— ëŒ€í•´ ì§ˆë¬¸í•˜ì„¸ìš” (ì˜ˆ: ê²°ì¸¡ì¹˜ê°€ ê°€ì¥ ë§ì€ ì»¬ëŸ¼ì€?)")

        if query:
            agent = create_pandas_dataframe_agent(llm, df, verbose=False)
            response = agent.run(query)
            st.session_state.chat_history.append((query, response))

        for q, a in st.session_state.chat_history:
            st.markdown(f"**ğŸ§‘ ì§ˆë¬¸:** {q}")
            st.markdown(f"**ğŸ¤– ë‹µë³€:** {a}")

# =========================
# ğŸ§© 4ï¸âƒ£ ì „ì²˜ë¦¬ íƒ­
# =========================
with tab4:
    if "dfs" not in st.session_state:
        st.warning("âš ï¸ ë¨¼ì € ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”.")
    else:
        df_names = list(st.session_state["dfs"].keys())
        selected_file = st.selectbox("ì „ì²˜ë¦¬í•  ë°ì´í„°ì…‹ ì„ íƒ", df_names)
        df = st.session_state["dfs"][selected_file]

        st.subheader("ğŸ§  AI ì „ì²˜ë¦¬ ì œì•ˆ")
        if st.button("ì „ì²˜ë¦¬ ì œì•ˆ ë°›ê¸°"):
            summary = {
                "shape": df.shape,
                "missing_values": int(df.isnull().sum().sum()),
                "duplicated_rows": int(df.duplicated().sum()),
                "columns": list(df.columns),
                "types": df.dtypes.astype(str).to_dict()
            }
            prompt = PromptTemplate.from_template("""
            ì•„ë˜ ë°ì´í„° ìš”ì•½ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì ì ˆí•œ ì „ì²˜ë¦¬ ë‹¨ê³„ë¥¼ ì œì•ˆí•´ì¤˜.
            (ì˜ˆ: ê²°ì¸¡ì¹˜ ì²˜ë¦¬, ì´ìƒì¹˜ ì œê±°, í˜•ë³€í™˜, ì¸ì½”ë”© ë“±)
            
            ë°ì´í„° ìš”ì•½:
            {summary}
            """)
            suggestion = llm.invoke(prompt.format(summary=json.dumps(summary, ensure_ascii=False)))
            st.session_state["ai_suggestion"] = suggestion.content
            st.write(suggestion.content)

        st.subheader("âš™ï¸ ì‚¬ìš©ì ì •ì˜ ì „ì²˜ë¦¬ ì‹¤í–‰")
        actions = st.text_area("ìˆ˜í–‰í•  ì „ì²˜ë¦¬ ëª…ë ¹ (ì˜ˆ: fillna=0, drop_duplicates, encode=label)")
        if st.button("ğŸš€ ì „ì²˜ë¦¬ ì‹¤í–‰"):
            df_clean = df.copy()
            try:
                if "fillna" in actions:
                    df_clean = df_clean.fillna(0)
                if "drop_duplicates" in actions:
                    df_clean = df_clean.drop_duplicates()
                if "encode" in actions:
                    from sklearn.preprocessing import LabelEncoder
                    enc = LabelEncoder()
                    for col in df_clean.select_dtypes(include=["object"]).columns:
                        df_clean[col] = enc.fit_transform(df_clean[col].astype(str))
                st.session_state["cleaned_df"] = df_clean
                st.success("âœ… ì „ì²˜ë¦¬ ì™„ë£Œ!")
                st.dataframe(df_clean.head())
            except Exception as e:
                st.error(f"ì „ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

# =========================
# ğŸ—ƒï¸ 5ï¸âƒ£ MySQL ì ì¬ íƒ­
# =========================
with tab5:
    if "cleaned_df" not in st.session_state:
        st.warning("âš ï¸ ë¨¼ì € ì „ì²˜ë¦¬ë¥¼ ì™„ë£Œí•˜ì„¸ìš”.")
    else:
        st.subheader("ğŸ—ƒï¸ MySQL ë°ì´í„°ë² ì´ìŠ¤ ì ì¬")

        host = st.text_input("MySQL í˜¸ìŠ¤íŠ¸", "localhost")
        port = st.text_input("í¬íŠ¸", "3306")
        user = st.text_input("MySQL ì‚¬ìš©ì", "root")
        password = st.text_input("MySQL ë¹„ë°€ë²ˆí˜¸", type="password")
        database = st.text_input("DB ì´ë¦„", "preprocessed_data")
        table_name = st.text_input("í…Œì´ë¸” ì´ë¦„", "cleaned_table")

        if st.button("ğŸ“¥ MySQL ì—…ë¡œë“œ"):
            try:
                engine = create_engine(f"mysql+pymysql://{user}:{password}@{host}:{port}/{database}")
                st.session_state["cleaned_df"].to_sql(
                    name=table_name,
                    con=engine,
                    if_exists="replace",
                    index=False
                )
                st.success(f"âœ… `{database}` DBì˜ `{table_name}` í…Œì´ë¸”ì— ì—…ë¡œë“œ ì™„ë£Œ!")
            except Exception as e:
                st.error(f"MySQL ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
