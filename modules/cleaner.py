import pandas as pd
import numpy as np
import unicodedata
import streamlit as st
from dateutil import parser
from datetime import datetime

# ==========================================================
# ğŸ§¹ 1ï¸âƒ£ ë¹„ì–´ ìˆëŠ” ì»¬ëŸ¼ ìë™ ì‚­ì œ
# ==========================================================
def drop_empty_cols(df: pd.DataFrame) -> pd.DataFrame:
    drop_cols = []
    for col in df.columns:
        if df[col].apply(lambda x: (pd.isna(x)) or (str(x).strip() == "")).all():
            drop_cols.append(col)
    if drop_cols:
        df = df.drop(columns=drop_cols)
        st.info(f"ğŸ—‘ï¸ ë¹„ì–´ ìˆëŠ” ì»¬ëŸ¼ ìë™ ì‚­ì œë¨: {', '.join(drop_cols)}")
    return df


# ==========================================================
# ğŸ§  2ï¸âƒ£ Robust ë‚ ì§œ íŒŒì„œ
# ==========================================================
def robust_parse_date(x):
    """datetime + dateutil.parser ë³‘í•© íŒŒì„œ"""
    if pd.isna(x) or str(x).strip() == "":
        return pd.NaT
    x = str(x).strip().replace("/", "-").replace(".", "-")
    for fmt in ("%Y-%m-%d", "%Y%m%d", "%Y-%m-%d %H:%M:%S"):
        try:
            return datetime.strptime(x, fmt)
        except ValueError:
            continue
    try:
        return parser.parse(x, fuzzy=True)
    except Exception:
        return pd.NaT


# ==========================================================
# ğŸ” 3ï¸âƒ£ ë‚ ì§œ ì¶”ì • í•¨ìˆ˜
# ==========================================================
def looks_like_date(val: str) -> bool:
    """ê°’ì´ ë‚ ì§œ í˜•íƒœë¡œ ë³´ì´ëŠ”ì§€ ê°„ë‹¨íˆ ì¶”ì •"""
    if not isinstance(val, str):
        return False
    val = val.strip()
    return bool(
        val
        and 6 <= len(val) <= 10
        and all(c.isdigit() or c in "-/." for c in val)
    )


# ==========================================================
# âš™ï¸ 4ï¸âƒ£ ë©”ì¸ ì „ì²˜ë¦¬ í•¨ìˆ˜
# ==========================================================
def preprocess_dataframe(df: pd.DataFrame, options: dict):
    df = df.copy()
    logs = []

    # 0ï¸âƒ£ ë¹ˆ ë¬¸ìì—´ì„ NaNìœ¼ë¡œ í†µì¼
    df = df.replace(r'^\s*$', np.nan, regex=True)

    # 1ï¸âƒ£ ë¬¸ìì—´ ê³µë°± ë° ìœ ë‹ˆì½”ë“œ ì •ê·œí™”
    if options.get("strip_strings", True):
        df = df.applymap(lambda x: unicodedata.normalize("NFKC", x.strip()) if isinstance(x, str) else x)
        logs.append("âœ… ë¬¸ìì—´ ì•ë’¤ ê³µë°± ë° ìœ ë‹ˆì½”ë“œ ì •ê·œí™”")

    # 2ï¸âƒ£ ëŒ€ì†Œë¬¸ì ë³€í™˜
    normalize_case = options.get("normalize_case")
    if normalize_case:
        if normalize_case == "lower":
            df = df.applymap(lambda x: x.lower() if isinstance(x, str) else x)
        elif normalize_case == "upper":
            df = df.applymap(lambda x: x.upper() if isinstance(x, str) else x)
        logs.append("âœ… ë¬¸ìì—´ ëŒ€ì†Œë¬¸ì ë³€í™˜ ìˆ˜í–‰")

    # 3ï¸âƒ£ ìˆ«ìí˜• ë¬¸ìì—´ ë³€í™˜ ("1,000", "$3000")
    if options.get("convert_numeric_strings", True):
        for col in df.columns:
            if df[col].dtype == object:
                cleaned = (
                    df[col].astype(str)
                    .str.replace(r"['\"]", "", regex=True)
                    .str.replace(r"[^\d\.\-]", "", regex=True)
                )
                numeric = pd.to_numeric(cleaned, errors="coerce")
                if numeric.notna().sum() > len(df) * 0.3:
                    df[col] = numeric
        logs.append("âœ… ìˆ«ìí˜• ë¬¸ìì—´ ë³€í™˜ ìˆ˜í–‰")

    if options.get("convert_dates", True):
        date_keywords = ["date", "day", "time", "dob", "birth", "dt"]
        for col in df.columns:
            if df[col].dtype != object:
                continue

            # â‘  ë‚ ì§œ ê°€ëŠ¥ì„± íŒë‹¨
            sample_values = df[col].dropna().astype(str).head(20).tolist()
            has_date_name = any(key in col.lower() for key in date_keywords)
            has_date_pattern = (
                sum(looks_like_date(v) for v in sample_values) / max(len(sample_values), 1)
            ) > 0.5

            if not (has_date_name or has_date_pattern):
                continue

            # â‘¡ ë¬¸ìì—´ ì „ì²˜ë¦¬ ë¨¼ì € ìˆ˜í–‰
            temp = (
                df[col].astype(str)
                .str.strip()
                .str.replace(r"[./]", "-", regex=True)
                .replace(["", " ", "NULL", "nan", "NaN", "None"], np.nan)
            )

            # â‘¢ 1ì°¨ pandas ë³€í™˜
            parsed = pd.to_datetime(temp, errors="coerce", infer_datetime_format=True)

            # â‘£ 2ì°¨ robust parser ì ìš© (NaTì¸ í•­ëª©ë§Œ)
            mask_failed = parsed.isna()
            if mask_failed.any():
                parsed.loc[mask_failed] = temp[mask_failed].apply(robust_parse_date)

            # â‘¤ ë³€í™˜ ê²°ê³¼ ë°˜ì˜
            df[col] = parsed

        # âœ… ë‚ ì§œ í¬ë§· í†µì¼
        for col in df.columns:
            if pd.api.types.is_datetime64_any_dtype(df[col]):
                df[col] = df[col].dt.strftime("%Y-%m-%d")

        logs.append("âœ… ë‚ ì§œí˜• ë³€í™˜ ì™„ë£Œ (ì›ë³¸ ë¬¸ìì—´ ìœ ì§€ í›„ robust ì²˜ë¦¬)")

    # 5ï¸âƒ£ Gender í‘œì¤€í™”
    if "Gender" in df.columns:
        df["Gender"] = (
            df["Gender"]
            .astype(str)
            .str.strip()
            .str.lower()
            .replace({
                "female": "F", "f": "F",
                "male": "M", "m": "M"
            })
        )
        logs.append("âœ… Gender ì»¬ëŸ¼ í‘œì¤€í™” (F/M)")

    # 6ï¸âƒ£ ê²°ì¸¡ì¹˜ ì±„ìš°ê¸°
    if options.get("fillna_zero", True):
        for col in df.columns:
            if pd.api.types.is_numeric_dtype(df[col]):
                df[col] = df[col].fillna(0)
            elif pd.api.types.is_datetime64_any_dtype(df[col]):
                df[col] = df[col].fillna(pd.Timestamp("1900-01-01"))
            else:
                df[col] = df[col].fillna("NULL")
        logs.append("âœ… ê²°ì¸¡ì¹˜ ì±„ìš°ê¸° ìˆ˜í–‰ (ìˆ«ì: 0, ë‚ ì§œ: 1900-01-01, ë¬¸ìì—´: 'NULL')")

    # 7ï¸âƒ£ ì¤‘ë³µ ì œê±°
    if options.get("drop_duplicates", False):
        before = len(df)
        df.drop_duplicates(inplace=True)
        logs.append(f"âš™ï¸ ì¤‘ë³µ í–‰ {before - len(df)}ê°œ ì œê±°")

    # 8ï¸âƒ£ ì™„ì „ ê³µë°± ì»¬ëŸ¼ ì œê±°
    if options.get("drop_empty_cols", True):
        df = drop_empty_cols(df)

    # 9ï¸âƒ£ ì»¬ëŸ¼ëª… ì •ë¦¬
    df.columns = [c.strip().replace(" ", "_") for c in df.columns]
    logs.append("âœ… ì»¬ëŸ¼ëª… ê³µë°± ì œê±° ë° ì–¸ë”ìŠ¤ì½”ì–´ ë³€í™˜")

    df.attrs["clean_log"] = logs
    return df
